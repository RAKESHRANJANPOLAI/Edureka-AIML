{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CRF-based Named Entity Recognition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Steve Neale - 2018"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook describes named entity recognition (NER) using conditional random fields or 'CRFs', which are very popular for this task. I've implemented the model using scikit-learn's 'sklearn-crfsuite' library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import warnings\n",
    "\n",
    "import pyprind\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import learning_curve\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn_crfsuite import CRF\n",
    "from sklearn_crfsuite import metrics\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.exceptions import UndefinedMetricWarning\n",
    "\n",
    "from model_plots import plot_learning_curve"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the NER dataset into a Pandas DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, the data is loaded into a Pandas DataFrame. This can be done easily using the `read_csv` function, specifying that the separator is a space. It's also useful to keep the blank lines, which are helpful later for determining the sentence breaks.\n",
    "\n",
    "Once the data is loaded into a DataFrame, the easy access we have to columns allows a couple of useful things to be done - group the data by the \"ne\" column to see the distributions of each tag, and extract the classes (disregarding 'O' and blank lines with NaN values) as a list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       ne  counts\n",
      "0   B-LOC    7140\n",
      "1  B-MISC    3438\n",
      "2   B-ORG    6321\n",
      "3   B-PER    6600\n",
      "4   I-LOC    1157\n",
      "5  I-MISC    1155\n",
      "6   I-ORG    3704\n",
      "7   I-PER    4528\n",
      "8       O  168346\n"
     ]
    }
   ],
   "source": [
    "# Read the NER data using spaces as separators, keeping blank lines and adding columns\n",
    "ner_data = pd.read_csv(\"./data/conll2003/train.txt\", sep=\" \", header=None, skip_blank_lines=False, encoding=\"utf-8\")\n",
    "ner_data.columns = [\"token\", \"pos\", \"chunk\", \"ne\"]\n",
    "\n",
    "# Explore the distribution of NE tags in the dataset\n",
    "tag_distribution = ner_data.groupby(\"ne\").size().reset_index(name='counts')\n",
    "print(tag_distribution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['B-ORG', 'B-MISC', 'B-PER', 'I-PER', 'B-LOC', 'I-ORG', 'I-MISC', 'I-LOC']\n"
     ]
    }
   ],
   "source": [
    "# Extract the useful classes (not 'O' or NaN values) as a list\n",
    "classes = list(filter(lambda x: x not in [\"O\", np.nan], list(ner_data[\"ne\"].unique())))\n",
    "\n",
    "print(classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract sentences from the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, sentences need to be extracted from the data - it's useful to have the sentences as a list of lists, with each sublist containing the token, POS tag, syntactic chunk, and NE label for every word token in the sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0% [##############################] 100% | ETA: 00:00:00\n",
      "Total time elapsed: 00:00:24\n"
     ]
    }
   ],
   "source": [
    "# Create a sentences dictionary and an initial single sentence dictionary\n",
    "sentences, sentence = [], []\n",
    "# Create a progress bar\n",
    "pbar = pyprind.ProgBar(len(ner_data))\n",
    "# For each row in the NER data...\n",
    "for index, row in ner_data.iterrows():\n",
    "    # If the row is empty (no string in the token column)\n",
    "    if type(row[\"token\"]) != str:\n",
    "        # If the current sentence is not empty, append it to the sentences and create a new sentence\n",
    "        if len(sentence) > 0:\n",
    "            sentences.append(sentence)\n",
    "            sentence = []\n",
    "    # Otherwise...\n",
    "    else:\n",
    "        # If the row does not indicate the start of a document, add the token to the current sentence\n",
    "        if type(row[\"token\"]) != float and type(row[\"pos\"]) != float and type(row[\"ne\"]) != float:\n",
    "            if not row[\"token\"].startswith(\"-DOCSTART-\"):\n",
    "                sentence.append([row[\"token\"], row[\"pos\"], row[\"chunk\"], row[\"ne\"]])\n",
    "    pbar.update()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract sentence features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The 'sklearn-crfsuite' website provides a tutorial on their CRF model, which contains example code for extracting word features as a dictionary ready-formatted for use with the model. The function below is based on their model, making use of:\n",
    "\n",
    "* Current words\n",
    "* Previous words\n",
    "* Next words\n",
    "* Current POS tags\n",
    "* Previous and next POS tags\n",
    "\n",
    "These features are all used in the Stanford NLP group's work on using CRFs for NER (Finkel et al., 2005). They also make use of a 'current word shape' feature, which generally shows the upper-cased letters, lower-cased letters, and digits that make up a word (For example, 'CoNLL-2003' => 'XxXXX-dddd'). In the 'sclearn-crfsuite' implementation below, the 'word.isupper()', 'word.istitle()', and 'word.isdigit()' features are used in place of this.\n",
    "\n",
    "The function below has also had a flag added to it to include chunk tags from the training data as features, for the current, previous, and next words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_features(sentence, i, use_chunks=False):\n",
    "    # Get the current word and POS\n",
    "    word = sentence[i][0]\n",
    "    pos = sentence[i][1]\n",
    "    # Create a feature dictionary, based on characteristics of the current word and POS\n",
    "    features = { \"bias\": 1.0,\n",
    "                 \"word.lower()\": word.lower(),\n",
    "                 \"word[-3:]\": word[-3:],\n",
    "                 \"word[-2:]\": word[-2:],\n",
    "                 \"word.isupper()\": word.isupper(),\n",
    "                 \"word.istitle()\": word.istitle(),\n",
    "                 \"word.isdigit()\": word.isdigit(),\n",
    "                 \"pos\": pos,\n",
    "                 \"pos[:2]\": pos[:2],\n",
    "               }\n",
    "    # If chunks are being used, add the current chunk to the feature dictionary\n",
    "    if use_chunks:\n",
    "        chunk = sentence[i][2]\n",
    "        features.update({ \"chunk\": chunk })\n",
    "    # If this is not the first word in the sentence...\n",
    "    if i > 0:\n",
    "        # Get the sentence's previous word and POS\n",
    "        prev_word = sentence[i-1][0]\n",
    "        prev_pos = sentence[i-1][1]\n",
    "        # Add characteristics of the sentence's previous word and POS to the feature dictionary\n",
    "        features.update({ \"-1:word.lower()\": prev_word.lower(),\n",
    "                          \"-1:word.istitle()\": prev_word.istitle(),\n",
    "                          \"-1:word.isupper()\": prev_word.isupper(),\n",
    "                          \"-1:pos\": prev_pos,\n",
    "                          \"-1:pos[:2]\": prev_pos[:2],\n",
    "                        })\n",
    "        # If chunks are being used, add the previous chunk to the feature dictionary\n",
    "        if use_chunks:\n",
    "            prev_chunk = sentence[i-1][2]\n",
    "            features.update({ \"-1:chunk\": prev_chunk })\n",
    "    # Otherwise, add 'BOS' (beginning of sentence) to the feature dictionary\n",
    "    else:\n",
    "        features[\"BOS\"] = True\n",
    "    # If this is not the last word in the sentence...\n",
    "    if i < len(sentence)-1:\n",
    "        # Get the sentence's next word and POS\n",
    "        next_word = sentence[i+1][0]\n",
    "        next_pos = sentence[i+1][1]\n",
    "        # Add characteristics of the sentence's previous next and POS to the feature dictionary\n",
    "        features.update({ \"+1:word.lower()\": next_word.lower(),\n",
    "                          \"+1:word.istitle()\": next_word.istitle(),\n",
    "                          \"+1:word.isupper()\": next_word.isupper(),\n",
    "                          \"+1:pos\": next_pos,\n",
    "                          \"+1:pos[:2]\": next_pos[:2],\n",
    "                        })\n",
    "        # If chunks are being used, add the next chunk to the feature dictionary\n",
    "        if use_chunks:\n",
    "            next_chunk = sentence[i+1][2]\n",
    "            features.update({ \"+1:chunk\": next_chunk })\n",
    "    # Otherwise, add 'EOS' (end of sentence) to the feature dictionary\n",
    "    else:\n",
    "        features[\"EOS\"] = True\n",
    "    # Return the feature dictionary\n",
    "    return features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the word_features function, a list of feature dictionaries for each word token in a sentence can be extracted, corresponding to a list of NE labels for each word token in a sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Return a feature dictionary for each word in a given sentence\n",
    "def sentence_features(sentence, use_chunks=False):\n",
    "    return [word_features(sentence, i, use_chunks) for i in range(len(sentence))]\n",
    "\n",
    "# Return the label (NER tag) for each word in a given sentence\n",
    "def sentence_labels(sentence):\n",
    "    return [label for token, pos, chunk, label in sentence]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split the sentences into training and test sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the predefined functions, X and y can be extracted as lists of feature dictionaries for each word token in each sentence, and as lists of NE labels for each word token in each sentence, respectively. scikit-learn's 'test_train_split' function can then be used to split X and y into training and test sets, split 80% training to 20% test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First token features:\n",
      "---------------------\n",
      "{'+1:word.lower()': 'entire', '+1:word.istitle()': False, 'word.lower()': 'the', 'pos': 'DT', 'word[-3:]': 'The', 'BOS': True, 'word.isupper()': False, 'word.istitle()': True, 'bias': 1.0, '+1:pos': 'JJ', '+1:word.isupper()': False, 'word[-2:]': 'he', '+1:pos[:2]': 'JJ', 'word.isdigit()': False, 'pos[:2]': 'DT'}\n",
      "\n",
      "First token label:\n",
      "------------------\n",
      "O\n"
     ]
    }
   ],
   "source": [
    "# For each sentence, extract the sentence features as X, and the labels as y\n",
    "X = [sentence_features(sentence) for sentence in sentences]\n",
    "y = [sentence_labels(sentence) for sentence in sentences]\n",
    "\n",
    "# Split X and y into training (80%) and test (20%) sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "\n",
    "print(\"First token features:\\n{}\\n{}\".format(\"-\"*21, X_train[0][0]))\n",
    "print(\"\\nFirst token label:\\n{}\\n{}\".format(\"-\"*18, y_train[0][0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train a CRF model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The training data can now be used to train a CRF (conditional random fields) model to map the feature dictionaries to output NE labels. CRF's have been a popular choice for training named entity recognition models following the success of the Stanford NLP group's work on NER (Finkel et al., 2005). The model employs the gradient descent-based L-BFGS algorithm, and uses elastic net (C1+C2) regularisation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CRF(algorithm='lbfgs', all_possible_states=None,\n",
       "  all_possible_transitions=True, averaging=None, c=None, c1=0.1, c2=0.1,\n",
       "  calibration_candidates=None, calibration_eta=None,\n",
       "  calibration_max_trials=None, calibration_rate=None,\n",
       "  calibration_samples=None, delta=None, epsilon=None, error_sensitive=None,\n",
       "  gamma=None, keep_tempfiles=None, linesearch=None, max_iterations=100,\n",
       "  max_linesearch=None, min_freq=None, model_filename=None,\n",
       "  num_memories=None, pa_type=None, period=None, trainer_cls=None,\n",
       "  variance=None, verbose=False)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a new CRF model\n",
    "crf = CRF(algorithm=\"lbfgs\",\n",
    "          c1=0.1,\n",
    "          c2=0.1,\n",
    "          max_iterations=100,\n",
    "          all_possible_transitions=True)\n",
    "\n",
    "# Train the CRF model on the supplied training data\n",
    "crf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evalute the CRF model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The trained model can now be used to make predictions based on the test data, which can in turn be compared to the expected labels from the test data to produce a classification report (precision, recall and F1 scores).\n",
    "\n",
    "The model is performing pretty well, with a 91% F1-score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "      B-ORG       0.91      0.88      0.90      1301\n",
      "     B-MISC       0.95      0.87      0.91       697\n",
      "      B-PER       0.92      0.92      0.92      1326\n",
      "      I-PER       0.93      0.96      0.95       894\n",
      "      B-LOC       0.93      0.93      0.93      1378\n",
      "      I-ORG       0.87      0.87      0.87       789\n",
      "     I-MISC       0.82      0.79      0.80       240\n",
      "      I-LOC       0.86      0.82      0.84       238\n",
      "\n",
      "avg / total       0.91      0.90      0.91      6863\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Use the CRF model to make predictions on the test data\n",
    "y_pred = crf.predict(X_test)\n",
    "print(metrics.flat_classification_report(y_test, y_pred, labels=classes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimise the model's parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's useful to see if we can improve performance at all by tuning some of the model's parameters. In this case, we can experiment with different parameters for the C1 and C2 values used for the elastic net regularisation.\n",
    "\n",
    "To do this, we can employ a cross-validated randomised search - an exhaustive grid search of all parameter combinations can also be done using scikit-learn, but this can get really computationally intensive. By limiting the randomised search to 50 iterations (random parameter combinations) and using 3-fold cross validation, we are essentially fitting 150 models, which is already quite intensive.\n",
    "\n",
    "Following the optimisation, we can see that lower values (increased regularisation strength) for both C1 and C2 values result in the best performing model - particularly for C1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 50 candidates, totalling 150 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:  2.4min\n",
      "[Parallel(n_jobs=-1)]: Done 150 out of 150 | elapsed:  9.9min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9007364726210794\n",
      "{'c1': 0.001, 'c2': 0.01}\n"
     ]
    }
   ],
   "source": [
    "# Set up a parameter grid to experiment with different values for C1 and C2\n",
    "param_range = [0.0001, 0.001, 0.01, 0.1, 1.0, 10.0, 100.0, 1000.0]\n",
    "param_grid = {\"c1\": param_range,\n",
    "              \"c2\": param_range}\n",
    "\n",
    "# Set up a bespoke scorer that will compare the cross validated models according to their F1 scores\n",
    "f1_scorer = make_scorer(metrics.flat_f1_score, average='weighted', labels=classes)\n",
    "\n",
    "# Perform a 3-fold cross-validated, randomised search of 50 combinations for different values for C1 and C2\n",
    "rs = RandomizedSearchCV(estimator=crf,\n",
    "                        param_distributions=param_grid,\n",
    "                        scoring=f1_scorer,\n",
    "                        cv=3,\n",
    "                        verbose=1,\n",
    "                        n_iter=50,\n",
    "                        n_jobs=-1)\n",
    "\n",
    "# Train the models in the randomised search, ignoring any 'UndefinedMetricWarning' that comes up \n",
    "with warnings.catch_warnings():\n",
    "    warnings.filterwarnings(\"ignore\", category=UndefinedMetricWarning)\n",
    "    rs.fit(X_train, y_train)\n",
    "\n",
    "# Print the model that scored highest in the randomised search, and the parameters it used\n",
    "print(rs.best_score_)\n",
    "print(rs.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate the optimised CRF model on the test data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, the optimised model can be used to make predictions based on the test data, which can in turn be compared to the expected labels from the test data to produce a classification report (precision, recall and F1 scores)\n",
    "\n",
    "The optimised model is performing slightly better, with precision, recall, and F1-score all having improved slightly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "      B-ORG       0.92      0.89      0.90      1301\n",
      "     B-MISC       0.95      0.89      0.91       697\n",
      "      B-PER       0.94      0.93      0.94      1326\n",
      "      I-PER       0.95      0.96      0.95       894\n",
      "      B-LOC       0.93      0.95      0.94      1378\n",
      "      I-ORG       0.89      0.88      0.88       789\n",
      "     I-MISC       0.84      0.80      0.82       240\n",
      "      I-LOC       0.87      0.83      0.85       238\n",
      "\n",
      "avg / total       0.92      0.91      0.92      6863\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Replace the CRF model with the best model from the randomised search\n",
    "crf = rs.best_estimator_\n",
    "\n",
    "y_pred = crf.predict(X_test)\n",
    "print(metrics.flat_classification_report(y_test, y_pred, labels=classes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create new training and test data using chunks as features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seeing as there are syntactic chunks included in our dataset, let's see if they make a difference when included as additional features in the training data. As before, the predefined functions can be used to extract X and y - lists of feature dictionaries for each word token in each sentence, and lists of NE labels for each word token in each sentence, respectively. This time, however, the 'use_chunks' flag has been set when extracting X.\n",
    "\n",
    "scikit-learn's 'test_train_split' function is again used to split X and y into training and test sets, split 80% training to 20% test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First token features:\n",
      "---------------------\n",
      "{'chunk': 'B-NP', 'word.lower()': 'the', 'word[-3:]': 'The', 'bias': 1.0, '+1:pos': 'JJ', 'word[-2:]': 'he', '+1:pos[:2]': 'JJ', 'word.isdigit()': False, '+1:chunk': 'I-NP', '+1:word.istitle()': False, '+1:word.lower()': 'entire', '+1:word.isupper()': False, 'pos': 'DT', 'BOS': True, 'word.isupper()': False, 'word.istitle()': True, 'pos[:2]': 'DT'}\n",
      "\n",
      "First token label:\n",
      "------------------\n",
      "O\n"
     ]
    }
   ],
   "source": [
    "# For each sentence, extract the sentence features as X, and the labels as y\n",
    "X = [sentence_features(sentence, use_chunks=True) for sentence in sentences]\n",
    "y = [sentence_labels(sentence) for sentence in sentences]\n",
    "\n",
    "# Split X and y into training (80%) and test (20%) sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "\n",
    "print(\"First token features:\\n{}\\n{}\".format(\"-\"*21, X_train[0][0]))\n",
    "print(\"\\nFirst token label:\\n{}\\n{}\".format(\"-\"*18, y_train[0][0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and evalute the optimised model using the w/chunks dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After training the optimised model on the training data that includes the chunks, predictions are made based on the test data, and then used to produce a classification report (precision, recall and F1 scores) by comparing it with the labels from the test data.\n",
    "\n",
    "The optimised model trained on the test data performs slightly better again, with precision now having risen to 93%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "      B-ORG       0.92      0.89      0.91      1301\n",
      "     B-MISC       0.95      0.88      0.91       697\n",
      "      B-PER       0.94      0.94      0.94      1326\n",
      "      I-PER       0.95      0.97      0.96       894\n",
      "      B-LOC       0.93      0.94      0.94      1378\n",
      "      I-ORG       0.89      0.88      0.88       789\n",
      "     I-MISC       0.82      0.80      0.81       240\n",
      "      I-LOC       0.88      0.83      0.86       238\n",
      "\n",
      "avg / total       0.93      0.91      0.92      6863\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Retrain the CRF model on the new training data\n",
    "crf.fit(X_train, y_train)\n",
    "\n",
    "# Use the CRF model to make predictions on the test data\n",
    "y_pred = crf.predict(X_test)\n",
    "print(metrics.flat_classification_report(y_test, y_pred, labels=classes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot learning curves for the optimised model (w/chunks dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The performance of the model can be evaluated using a learning curve, plotting the accuracy of predictions on the training and test datasets as more training data is fed to the model. As we'd expect, the accuracy on the test data increases with the number of training samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[learning_curve] Training set sizes: [ 748 1497 2246 2995 3744 4492 5241 5990 6739 7488]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  30 out of  30 | elapsed:  1.5min finished\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Produce the necessary data for a learning curve\n",
    "train_sizes, train_scores, test_scores = learning_curve(estimator=crf,\n",
    "                                                        X=X_train,\n",
    "                                                        y=y_train,\n",
    "                                                        train_sizes=np.linspace(0.1, 1.0, 10),\n",
    "                                                        cv=3,\n",
    "                                                        verbose=1,\n",
    "                                                        n_jobs=-1)\n",
    "\n",
    "# Find the means and standard deviations of the training and test datasets across the learning curve\n",
    "train_mean = np.mean(train_scores, axis=1)\n",
    "train_std = np.std(train_scores, axis=1)\n",
    "test_mean = np.mean(test_scores, axis=1)\n",
    "test_std = np.std(test_scores, axis=1)\n",
    "\n",
    "# Plot the learning curve\n",
    "plot_learning_curve(train_sizes, train_mean, train_std, test_mean, test_std)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is still a bit of a gap between the test and training accuracy, suggesting that the model is perhaps a little overfit to the training data. More training data, or experimentation with new/different feature combinations might negate this going forwards. Features that could be added or experimented with might include:\n",
    "\n",
    "* Character n-grams (used for current words by Finkel et al. (2005))\n",
    "* True word shapes (current implementation only returns whether the whole word is made of upper-cased letters of digits, or if the word starts with a capital letter, but doesn't flag words that combine upper/lower-cased letter and digits)\n",
    "* Presence of the current word in a left or right window of given size (used by Finkel et al. (2005))\n",
    "* The value of the current word bias (currently left at 1.0 for every word)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finkel, J.R., Grenager, T. & Manning, C. (2005). 'Incorporating Non-local Information into Information Extraction Systems by Gibbs Sampling'. In Proceedings of the 43rd Annual Meeting of the Association for Computational Linguistics (ACL '05). pp. 363–370.\n",
    "\n",
    "sklearn-crfsuite (n.d.). 'Tutorial - scklearn-crfsuite 0.3 documentation' [https://sklearn-crfsuite.readthedocs.io/en/latest/tutorial.html#features]. Accessed 2018-11-30."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
